---
title: "p8105_hw6_hh2767"
author: "Haoran Hu"
date: "2018-11-22"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rvest)
library(httr)
library(mgcv)
library(modelr)

knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 8,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_bw() + theme(legend.position = "bottom"))
```

#Problem 1

##Read and describe the dataset

```{r}

homicide = GET("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") %>% 
  content("raw") %>% 
  read_csv()

str(homicide)
  
```

The raw dataset contains `r ncol(homicide)` variables and `r nrow(homicide)` observations. It contains information about `r nrow(homicide)` homicides occured in the US. The variables in this dataset are:

* `uid`: homicide id
* `reported_date`: reported date
* `victim_last`: last name of victim
* `victim_first`: first name of victim
* `victim_race`: race of victim
* `victim_age`: age of victim
* `victim_sex`: sex of victim
* `city`: city of the homicides
* `state`: state of the homicides
* `lat`: occurrence latitude
* `lon`: occurence longitude
* `disposition`: result of investigation

The location, time, and information of victims of each homicide are included in the dataset. The dataset also indicates whether the homicides are solved or not.

##Adding variables and tidying the dataset

In the following part, I will:

* create a `sity_state` variable which shows the city and state of occurence

* add a binary variable indicating whether the homicide is solved

* omit cities Dallas, TX; Phoenix, AZ; Kansas City, MO; and Tulsa, AL 

* modifiy `victim_race` to have categories white and non-white, with white as the reference category

* change `victim_age` to numeric variable

```{r}
homicide = homicide %>% 
  mutate(city_state = str_c(city, ",", state),
         resolved = as.numeric(disposition == "Closed by arrest"),
         victim_race = as.factor(ifelse(victim_race == "White", "white", "non-white")),
         victim_race = relevel(victim_race, ref = "white"),
         victim_age = as.numeric(victim_age)
         ) %>%
  filter(!city_state %in% c("Dallas,TX", "Phoenix,AZ", "Kansas City,MO", "Tulsa,AL")) 

str(homicide)
```

##Logistic regression for Baltimore

In this part, I will:

* Focus on the city of Baltimore, MD

* use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race (as just defined) as predictors

* save the output of glm as an R object

* apply the `broom::tidy` to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed

```{r}
baltimore_logistic = 
  homicide %>% 
  filter(city == "Baltimore") %>%
  glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial())


baltimore_race_OR = baltimore_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate)) %>% 
  cbind(., 
        exp(baltimore_logistic %>% 
  broom::confint_tidy())) %>% 
  filter(term == "victim_racenon-white") %>% 
  mutate(city = "Baltimore, MD") %>% 
  select(city,term, OR, '95% conf.low' = conf.low, '95% conf.high' = conf.high) 

baltimore_race_OR %>% 
  knitr::kable(digits = 3)
```

The table above shows the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed. The estimated adjusted odds ratio is `r round(baltimore_race_OR$OR, 3)`, which means that the murdered non-white people have `r round(baltimore_race_OR$OR, 3)` times the odds of having the homicide solved when compared with white people. The 95% confidence interval for the adjusted OR is [`r round(baltimore_race_OR$'95% conf.low', 3)`, `r round(baltimore_race_OR$'95% conf.high', 3)`] 

##Apply the process described above to each city

In this part, I will:

* build a function to run glm for each of the cities in the dataset

* extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims

* making use of purrr::map, list columns, and unnest

```{r}
get_or_race = function(city_data){
  
  city_logistic = 
  city_data %>% 
  glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial())

  city_race_OR = city_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate)) %>% 
  cbind(., 
        exp(city_logistic %>% 
  broom::confint_tidy())) %>% 
  filter(term == "victim_racenon-white") %>% 
  select(`adjusted OR for solving homicides` = OR, '95% conf.low' = conf.low, '95% conf.high' = conf.high) 
  
  round(city_race_OR, 3)
}


homicide_race_or = homicide %>% 
  filter(victim_sex != "Unknown") %>% 
  select(city_state, victim_age, victim_race, victim_sex, resolved) %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(or_race = map(data, ~get_or_race(.x))) %>% 
  select(-data) %>% 
  unnest()

str(homicide_race_or)

```

The data frame `homicide_race_or` contains estimated ORs and CIs for each city.

##Making a plot to show the estimated ORs and CIs

Next, I will make a plot to show the estimated ORs and CIs for each city

```{r}

homicide_race_or %>% 
  mutate(city_state = forcats::fct_reorder(city_state, `adjusted OR for solving homicides`)) %>% 
  ggplot(.) +
  geom_point(aes(x = city_state, y =  `adjusted OR for solving homicides`), color = "brown1") +
  geom_errorbar( aes(x = city_state, ymin = `95% conf.low`, ymax = `95% conf.high`)) +
  labs(title = "Adjusted OR of solving homicides(comparing white with non-white people)", x = "City", y = "Adjusted OR of solving homicides") +
  theme(axis.text.x = element_text(face = "plain", color = "black", size = 6.5, angle = 90), legend.position = "null")
```

#Problem2

##Loading and cleaning the data

```{r}
birthweight = GET("http://p8105.com/data/birthweight.csv") %>% 
  content("raw") %>% 
  read_csv()

birthweight_model = 
  birthweight %>% 
  mutate(babysex = factor(babysex, levels = c(1, 2), labels = c("male", "female")),
         frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), labels = c("white", "black", "asian", "puerto tican", "other", "unknown")),
         mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), labels = c("white", "black", "asian", "puerto tican", "other")),
         malform = factor(malform, labels = c("absent", "present")))



str(birthweight_model)
```

Now, the dataset we get is a `r nrow(birthweight_model)` (observation) * `r ncol(birthweight_model)` (variables) dataset, the variables are:
  
  * `babysex`: baby's sex (male, female)
  
  * `bhead`: baby's head circumference at birth (centimeters)
  
  * `blength`: baby's length at birth (centimeteres)
  
  * `bwt`: baby's birth weight (grams)
  
  * `delwt`: mother's weight at delivery (pounds)
  
  * `fincome`: family monthly income (in hundreds, rounded)
  
  * `frace`: father's race (White, Black, Asian, Puerto Rican, Other, Unknown)
  
  * `gaweeks`: gestational age in weeks
  
  * `malform`: presence of malformations that could affect weight (absent, present)
  
  * `menarche`: mother's age at menarche (years)
  
  * `mheigth`: mother's height (inches) 
  
  * `momage`: mother's age at delivery (years)
  
  * `mrace`: mother's race (White, Black, Asian, Puerto Rican, Other)
  
  * `parity`: number of live births prior to this pregnancy
  
  * `pnumlbw`: previous number of low birth weight babies 
  
  * `pnumgsa`: number of prior small for gestational age babies
  
  * `ppbmi`: mother's pre-pregnancy BMI
  
  * `ppwt`: mother's pre-pregnancy weight (pounds)
  
  * `smoken`: average number of cigarettes smoked per day during pregnancy
  
  * `wtgain`: mother's weight gain during pregnancy (pounds)
  
  Next, I will check the distribution of the outcome(birthweight).
  
```{r}
birthweight_model %>% 
  ggplot(aes(x = bwt)) + 
  geom_histogram(fill = "navy") + 
  labs( x = "Birthweight (grams)")
```
  
  As the plot shows, birthweight is approximately normally distributed, and we don't need to do transformation on it.
  
##Selecting predictors for the model
  
  First, we check the collinearity between the varibles and drop some of the correlated variables.
  
```{r warning = FALSE}
birthweight %>% 
  cor() %>% 
  knitr::kable(digits = 2)

```
   
As the result shows, the correlation between `pnumlbw` and `pnumsga`, and other variables are not computed. That's probably because the values of the two variables are always zero in the dataset. Therefore, the two variables do not provide any information to us, and we exclude them from the dataset.

In addition, two sets of predictors have high correlations:

1. `bhead` and `blength`

2. `delwt` and `ppwt` and `ppbmi`

In the first set, I will keep `bhead` because it has higher correlation with `bwt`. In the second set, I will keep `ppbmi` because it integrates information on `ppwt` and `mheight`. In this case, we can also drop `mheight`because the information is contained in `ppbmi`. 

After searching for some information from the internet, I found there are evidence that presence of malformations of the mother, number of live births prior to this pregnancy of the mother, mother's age at menarche, and mother's age are not closely relevant to baby's weight. Therefore, I will further exclude `malform`, `menarche`, `momage`, and `parity`, and keep the rest of variables in the model.

We call it Model 1.

Model 1:

bet ~ `babysex` + `bhead` + `fincome` + `frace` + `gaweeks` + `mrace` + `ppbmi` + `smoken` + `wtgain`

##Fitting and describing the model

```{r}
birthweight_fit1 = lm(bwt ~ babysex + bhead + blength + fincome +frace + gaweeks + mrace + ppbmi + smoken + wtgain, data = birthweight_model)

summary(birthweight_fit1) 
```

The summary of the linear regression model is as above. The adjusted R-square is 0.7133 and that means the model fits well.

```{r}
birthweight_model %>% 
  modelr::add_predictions(birthweight_fit1) %>% 
  modelr::add_residuals(birthweight_fit1) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  labs(title = "Fitted values vs. residuals plot", 
       x = "Fitted value", 
       y = "Model residual")
```

As the plot shows, when fitted value is above 2000 grams, which is the most common range of fitted values, the equal variance assumption of residuals holds true. When fitted value is below 2000 grams, the equal variance assumption seems to be violated, but that's because there are not many data points in that range, and the smooth curve might be driven off by those outliers. Therefore, in general, the plot does not reject the validity of the model.

##Comparing the model with two others

In this part, I will compare the following three models:

1. The model that I established in last section:

birthwtfit_my : `bwt` ~ `babysex` + `bhead` + `blength` + `fincome` +`frace` + `gaweeks` + `mrace` + `ppbmi` + `smoken` + `wtgain`

2. A model using length at birth and gestational age as predictors (main effects only):

birthwtfit_1 : `bwt` ~ `blength` + `gaweeks`

3. A model using head circumference, length, sex, and all interactions (including the three-way interaction) between these:

birthwtfit_2 : `bwt` ~ `babysex` + `blength` + `bhead` + `babysex * blength` + `babysex * bhead` + `blength * bhead` + `babysex * blength * bhead`

```{r}
  
cv_bwt =
    crossv_mc(birthweight_model, 100) %>% 
    mutate(
         train = map(train, as_tibble),
         test = map(test, as_tibble)
         ) %>% 
    mutate(
        birthwtfit_my = map(train, ~lm(bwt ~ babysex + bhead + blength + fincome +frace + gaweeks + mrace + ppbmi + smoken + wtgain, data = .x)),
        birthwtfit_1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
        birthwtfit_2 = map(train, ~lm(bwt ~ babysex + blength + bhead + babysex * blength + babysex * bhead + blength * bhead + babysex * blength * bhead, data = .x))
        ) %>% 
    mutate(
        rmse_birthwtfit_my = map2_dbl(birthwtfit_my, test, ~rmse(model = .x, data = .y)),
        rmse_birthwtfit_1 = map2_dbl(birthwtfit_1, test, ~rmse(model = .x, data = .y)),
        rmse_birthwtfit_2 = map2_dbl(birthwtfit_2, test, ~rmse(model = .x, data = .y))
    )

cv_bwt %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + 
    geom_violin() +
    labs(title = "Violin plots of rmse")
```

Based on these results, my model has the lowest rmse, which means it has the best predictive accuracy among the three. The model `birthwtfit_2` has slightly lower predictive accuracy, and the model`birthwtfit_1` is the least accurate. Therefore, I will go with my model.
